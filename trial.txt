from langchain_cohere import ChatCohere
from operator import itemgetter
from typing import Dict, Optional
from langchain.prompts import ChatPromptTemplate
from langchain.schema import StrOutputParser
from langchain.schema.runnable import Runnable
from langchain.schema.runnable.config import RunnableConfig
from typing import cast
from langchain.memory import ConversationBufferMemory
from datetime import datetime
from chainlit.types import ThreadDict

import chainlit as cl

import getpass
import os

from langchain_core.prompts import MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough, RunnableLambda

if "COHERE_API_KEY" not in os.environ:
    os.environ["COHERE_API_KEY"] = getpass.getpass()

#React
def setup_runnable():
    memory = cl.user_session.get("memory")  # type: ConversationBufferMemory
    model = ChatCohere(streaming=True)
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "Hey there! I'm Simba, your go-to for all things 'Bano'—the classic Kenyan marble game! "
                "Before we jump in, what's your name? Also, how’s your day going? "
                "Once you're ready, I'll take you through everything—how to set up, the rules, cool strategies, and how to win. "
                "Let’s chat!",
            ),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}"),
        ]
    )





    runnable = (
            RunnablePassthrough.assign(
                history=RunnableLambda(memory.load_memory_variables) | itemgetter("history")
            )
            | prompt
            | model
            | StrOutputParser()
    )
    cl.user_session.set("runnable", runnable)



@cl.oauth_callback
def oauth_callback(provider_id: str, token: str, raw_user_data: Dict[str, str], default_user: cl.User) -> Optional[cl.User]:
    return default_user

@cl.on_chat_start
async def on_chat_start():
    image = cl.Image(path="opener.jpg", name="image1", display="inline")
    cl.user_session.set("memory", ConversationBufferMemory(return_messages=True))
    app_user = cl.user_session.get("user")

    # Determine the appropriate greeting based on the current time
    current_hour = datetime.now().hour
    if current_hour < 12:
        greeting = "Good morning"
    elif current_hour < 18:
        greeting = "Good afternoon"
    else:
        greeting = "Good evening"
    await cl.Message(f"{greeting}, {app_user.identifier}!",elements=[image]).send()
    setup_runnable()


@cl.on_chat_resume
async def on_chat_resume(thread: ThreadDict):
    memory = ConversationBufferMemory(return_messages=True)
    root_messages = [m for m in thread["steps"] if m["parentId"] == None]
    for message in root_messages:
        if message["type"] == "user_message":
            memory.chat_memory.add_user_message(message["output"])
        else:
            memory.chat_memory.add_ai_message(message["output"])

    cl.user_session.set("memory", memory)

    setup_runnable()


@cl.on_message
async def on_message(message: cl.Message):
    memory = cl.user_session.get("memory")  # type: ConversationBufferMemory

    runnable = cl.user_session.get("runnable")  # type: Runnable

    res = cl.Message(content="")

    async for chunk in runnable.astream(
            {"question": message.content},
            config=RunnableConfig(callbacks=[cl.LangchainCallbackHandler()]),
    ):
        await res.stream_token(chunk)

    await res.send()

    memory.chat_memory.add_user_message(message.content)
    memory.chat_memory.add_ai_message(res.content)